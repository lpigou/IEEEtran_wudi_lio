\newcommand{\rev}[1]{{\noindent {\bf Comment:} {\it #1}}~\\[-2mm]}
\newcommand{\ans}[1]{{\noindent {\bf Response:} #1}~\\[-2mm]}
\newcommand{\td}[1]{{\noindent {\bf TODO:} #1}~\\}


\newcommand{\PM}[1]{
~\\[-4mm]
%``\dots{\em #1}\ldots''
``{\em #1}''
}


% -----------------------------------------------------------------------------------
\newpage
{\LARGE \noindent Response to Reviewer 1}\newline

\rev{
After reading the responses and revised paper, I am happy to say that my confusions and criticisms are rebutted. I thank the authors for their diligence in indulging my requests for clarification and additional experiments. I believe the paper is much improved and should be accepted.

Specifically:

- The additional discussion convinced me of sufficient contribution (jointly learning features and emission probabilities from heterogeneous input streams for gesture recognition).
	
- I agree with the authors that ``More investigation on how to handle heterogeneous networks should be conducted". The additional experiments have identified important problems
(e.g. differences in mean activation) for future work, which is a contribution in itself. In Sec 5.3, Late vs. Intermediate fusion: If done right, the intermediate fusion should work at-least-as-well as the late fusion? But, as the authors discuss, it is not trivial to `do it right'. I think they have done their due-diligence here and, importantly, exposed a problem.

- The qualitative analysis is greatly improved, giving insight.

- I am happy to see intermediate fusion and fine tuning have been considered.

 After reading the rebuttal and spending some time searching the literature I agree the work is new and interesting. The authors identify problems and
challenges for future work. It isn't a revolutionary paper, but it seems an important and valid milestone which contributes understanding to our community.
}

\ans{
Thank you for your review and recognition of the improvement of the revised paper. The suggestions from the reviewers are also valuable resources for us to better understand the proposed algorithm and make better reflective experimental analysis.
}


\rev{
Below I enumerate my few remaining concerns, which I believe the authors
should consider in a minor revision:
A few minor substantive points:
4.1: You might consider a latent variable model for the state labels $y_{i,t}$ instead of `force alignment'. It might help to briefly justify why you think forced assignment is good enough.
}

\ans{
Thank you for your insightful comments. We did encounter similar thoughts when implementing the system as speech processing researchers previously have done.
We have incorporated a brief discussion in ``For speech recognition community~\cite{yu2012automatic}, a common approach is to adopt the trained GMM-HMM to have the alignment labels and use them for the DNNs. Although we could potentially adopt the same route, the contribution to the quality of the labels may be trivial considering the increase of the training time. Hence, we argue that the forced alignment scheme will suffice."
Therefore, we did not digress into this point as another potential contribution of the paper.
}

\rev{
Figure 8: Label the y-axis on the figure. The information is in the caption, but readers are lazy.
}


\ans{
We have updated the annotated x-axis and y-axis for Figure 8.
}

\rev{
A few minor grammatical problems:
The authors jointly learn features and emission probabilities from
*heterogeneous input streams* for dynamic gesture recognition.
}

\ans{
Thank you for the careful review. We have thoroughly corrected the grammatical problems throughout the paper in this revision.
}


% -----------------------------------------------------------------------------------
\newpage
{\LARGE \noindent Response to Reviewer 2}\newline

\rev{
The authors made an excellent effort to improve the paper based on all the reviewers' comments. The paper proposes the fusion of the output from a Gaussian-Bernoulli Deep Belief network operating on skeletal features and the output of a Convolutional Neural Network operating on RGBD data to perform gesture segmentation and recognition.  The paper advances the field of gesture recognition by using both data sources and deep learning architectures within a Hidden Markov Model chain. The results are improved compared to using either architecture independently.

The revised version of the paper includes another fusion scheme: instead of averaging the outputs of the two networks (called ``late fusion"), the paper proposes to concatenate the high-level representations produced by their penultimate layers and process them through another classification layer to get the emission probabilities (called ``intermediate fusion"). Unfortunately, this type of fusion, which made more sense to me, performs slightly worse. I suspect that the reason is that different types of units (\emph{ReLU} vs sigmoid units) are used in the two networks causing incompatible scales in the outputs of the penultimate layers, as the authors indicate. In any case, this add-on is useful and can inspire future investigation on this topic and better implementations.
I recommend acceptance.
}

\ans{
Thank you for your review and positive outlook of the revised paper. The suggestions from the reviewers were also a stimulus spur for us to have a better analysis of the proposed method. We also agree that our fusion method exposes a problem for future investigation which is also a contribution in itself.
}


\rev{
I recommend the authors to make an additional pass to correct typos e.g. combinatin $\rightarrow$ combination.
}

\ans{
Thank you for your careful review. We have proof read the paper and corrected the grammatical mistakes accordingly.
}

% -----------------------------------------------------------------------------------
\newpage
{\LARGE \noindent Response to Reviewer 3}\newline

\rev{
In this second revision, readability and organization of the manuscript have been significantly improved. Additional experiments have been conducted, and interesting insights and discussions have been added, including comparison of intermediate vs late fusion and temporal modeling vs aggregation of per-frame predictions by voting. Finally, more consistent and complete overview of related work is included.
There are no changes in the method though: it remains interesting from a practical point of view, but not particularly novel.
}


\ans{

Thank you for your recognition of the improvement of the readability and organisation of the paper. The reviewing process also helps us to better understand and analysis the proposed model.
From the reviewing process and the experiments conducted for intermediate fusion, we investigate the difference of mean activations in intermediate fusion due to different activation functions are analysed which is a contribution itself so as to spur further investigation to effectively fuse multi-model, various activations.

}

\rev{
In section II, please note that a year earlier, ChaLearn 2013 competition was dominated by exploiting HMMs (also RNNs) for the same task and on the same dataset.
http://gesture.chalearn.org/2013-multi-modal-challenge/workshop-2013-challenge
Some works are published:
\begin{itemize}
\item HMM:Fusing multi-modal features for gesture recognition, ICMI workshop, 2013
\item HMM:Nandakumar et al., A Multi-modal Gesture Recognition System Using Audio, Video, and Skeletal Joint Data, ICMI workshop, 2013
\item RNN:Neverova et al., A multi-scale approach to gesture detection and recognition, ICCV workshop, 2013
\end{itemize}
}


\ans{

Thank you for the suggested related works. They are very relevant to the paper and the problem that the proposed system is trying to solve. We have included the discussions of the suggested works in the Section:
``Recently, the gesture recognition domain has been stimulated by the collection and publication of large corpora.
One such corpus was made available for the ChaLearn 2013 competition, in which HMM models were used by many participants:
%
Nandakumar \emph{et al.}~\cite{nandakumar2013multi} applied the MFCC+HMM paradigm for audio input while their visual module still relied on low level features such as Space-Time-Interest-Point (STIP) or covariance descriptor to process RGB videos and skeleton models.
%
The 1st ranked team, Wu \emph{et al.}~\cite{wu2013fusing}, used and HMM model as audio feature classifier and Dynamic Time Warping as the classifier for skeleton features.  A Recurrent Neural Network (RNN) was utilized in~\cite{neverova2013multi} to model large-scale temporal dependencies, for data fusion and for the final gesture classification.  Interestingly, the system in ~\cite{neverova2013multi} decomposed the gestures into a large-scale body motion and local subtle movements."
The key differences between the aforementioned papers and the proposed approach is that we use HMM for modelling hidden stats of gesture over the joint feature space whilst their HMM models are purely for audio input~\cite{nandakumar2013multi,wu2013fusing}. Our proposed system uses DBN with pre-training to learn the skeleton features instead of the hand crafted features~\cite{neverova2013multi}. Moreover, we explore the late and intermediate fusion scheme instead of the weighted likelihood that is adopted by~\cite{nandakumar2013multi}. Albeit the intermediate fusion scheme does not outperform late fusion, the discrepancy is a contribution in itself.

}

\rev{
Some sections of the manuscript require additional proof reading: please check for typos (they are many, especially in section III), verb endings and spelling of names in your references.
}

\ans{
Thank you for your careful review. We have proof read the paper and corrected the grammatical mistakes accordingly.
}

\rev{
In terms of performance, the described DBN for treating raw skeleton data looks promising (16.5\% validation error), while 3D Convnets on depth and intensity images perform, unfortunately, poorly (39\% validation error), especially taking into account that two kinds of input (hands and full body) are combined. Why not get some insights from existing state of the art architectures (from [57], for example), and further improve them by adding full body processing and better modeling of temporal dependencies?
}

\ans{

Thank you for your comment. We are also aware of the promising aspect for utilizing DBN for raw skeleton data, nonetheless the less promising 3DCNN module for depth and intensity images.
One contribution of the paper is
``The difference of mean activations in intermediate fusion due to different activation functions is
analysed which is a contribution itself so as to spur further investigation to effectively fuse multi-
model, various activations."
In terms of the parallel work of \emph{Neverova et al.}, due to the main processing stream and the scope of the paper, we propose the analysis in the future work to combine their architecture and fuse various modules.



}

\endinput
